---
title: "assignment2"
author: "Sergimayol"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 2

```{r}
library("car")
library(ggplot2)
library(gridExtra)
```

## Data

```{r Prestige}
?Prestige
dataset <- Prestige
```

### Questions

1.- Give a summary of the Prestige data frame. Indicate the size (number of observations and variables) and type of variables.

-   The summary will be the following:

```{r}
summary(dataset)
```

-   The size (number of observations and variables):

```{r}
dim(dataset)
```

-   The type of the variables:

```{r}
str(dataset)
```

2.- The focus in this assignment is the regression model, where "income" will be the dependent variable. Draw different plots to see the relationship between the variables.

```{r}
df <- dataset
```

```{r}
grid_layout <- grid.arrange(
  ggplot(df, aes(x=income, y=education)) + geom_point() + ggtitle("Income vs. Education"),
  ggplot(df, aes(x=income, y=prestige)) + geom_point() + ggtitle("Income vs. Prestige"),
  ggplot(df, aes(x=income, y=type)) + geom_point() + ggtitle("Income vs. Type"),
  ggplot(df, aes(x=income, y=women)) + geom_point() + ggtitle("Income vs. Women"),
  ggplot(df, aes(x=income, y=census)) + geom_point() + ggtitle("Income vs. Census"),
  ncol = 3
)
grid_layout
```

3.- Consider only variables "income" and "education". Draw a histogram for variable "income". Draw the boxplot for "education". Draw a scatterplot of both variables to see their relationship. Fit a linear regression and see how well this model fits the observed data. Draw the model over the scatterplot. What do you observe? Do the regression assumptions hold?

- Histogram for the `income` variable:

```{r}
ggplot(df, aes(x = income)) +
  geom_histogram(binwidth = 5000, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Income", x = "Income", y = "Frequency")
```

- Boxplot for the `education` variable:

```{r}
ggplot(df, aes(y = education)) +
  geom_boxplot() +
  labs(title = "Boxplot of Education", y = "Education")
```

- Scatter plot of `education vs income`:

```{r}
ggplot(df, aes(x = education, y = income)) +
  geom_point() +
  labs(title = "Scatter Plot of Education vs Income", x = "Education", y = "Income")
```

- Linear regression on the observed data:

```{r}
ggplot(df, aes(x=education, y=income)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="Regression Plot: Education vs. Income", x="Education", y="Income")
```

As the result above shows, ... TODO

4.- Consider the polynomial regression model. How well does the polynomial model fit the data? Compare the R2 of both linear and polynomial models. What do you conclude?

```{r}
model <- lm(income ~ poly(education, 2), data = df)

scatter_plot <- ggplot(df, aes(x = education, y = income)) +
  geom_point() +
  labs(title = "Education vs Income", x = "Education", y = "Income")

scatter_plot + geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, col = "red") +
  labs(title = "Polynomial Regression: Education vs Income")
```

As it can be seeing above, the polynomial regression model ($R^2$), ... TODO

- Comparation between the Linear regression and Polynomial regression model, side to side:

```{r}
linear_reg_plot <- ggplot(df, aes(x=education, y=income)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="Regression Plot: Education vs. Income", x="Education", y="Income")

scatter_plot <- ggplot(df, aes(x = education, y = income)) +
  geom_point() +
  labs(title = "Education vs Income", x = "Education", y = "Income")

poly_reg_plot <- scatter_plot + geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, col = "red") + labs(title = "Polynomial Regression: Education vs Income")

grid_layout <- grid.arrange(
  linear_reg_plot,
  poly_reg_plot,
  ncol = 2
)
grid_layout
```

It can be seeing that, ... TODO

So it can be concluded that, ... TODO

5.- Would some transformation procedure of the variables, such as log or square root, allow for a better model? Try out different transformations and plot the transformed variables. Which transformation is the "best"? For the best transformation, fit a regression model.


