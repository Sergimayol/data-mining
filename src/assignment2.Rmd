---
title: "Assignment 2 - Regression models"
author: "Sergimayol"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

For this assignment, the following libraries are used:

```{r}
library(car)
library(ggplot2)
library(gridExtra)
```

## Data

This assignment uses the data frame Prestige included in the “car” package.

```{r Prestige}
?Prestige
dataset <- Prestige
```

### Questions

1.- Give a summary of the Prestige data frame. Indicate the size (number of observations and variables) and type of variables.

-   The summary will be the following:

```{r}
summary(dataset)
```

-   The size (number of observations and variables):

```{r}
dim(dataset)
```

-   The type of the variables:

```{r}
str(dataset)
```

2.- The focus in this assignment is the regression model, where "income" will be the dependent variable. Draw different plots to see the relationship between the variables.

To simply the naming of the dataset it can be renamed to `df`

```{r}
df <- dataset
```

Using `gglplot` and `gridExtra` libraries, it's possible to plot relationship between the variables.

```{r}
grid_layout <- grid.arrange(
  ggplot(df, aes(x=education, y=income )) + geom_point() + ggtitle("Income vs. Education"),
  ggplot(df, aes(x=prestige, y=income )) + geom_point() + ggtitle("Income vs. Prestige"),
  ggplot(df, aes(x=women, y=income )) + geom_point() + ggtitle("Income vs. Women"),
  ggplot(df, aes(x=census, y=income )) + geom_point() + ggtitle("Income vs. Census"),
  ggplot(df, aes(x=type, y=income )) + geom_point() + ggtitle("Income vs. Type"),
  ncol = 3
)
grid_layout
```

3.- Consider only variables "income" and "education". Draw a histogram for variable "income". Draw the boxplot for "education". Draw a scatterplot of both variables to see their relationship. Fit a linear regression and see how well this model fits the observed data. Draw the model over the scatterplot. What do you observe? Do the regression assumptions hold?

- Histogram for the `income` variable:

```{r}
ggplot(df, aes(x = income)) +
  geom_histogram(binwidth = 5000, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Income", x = "Income", y = "Frequency")
```

- Boxplot for the `education` variable:

```{r}
ggplot(df, aes(y = education)) +
  geom_boxplot() +
  labs(title = "Boxplot of Education", y = "Education")
```

- Scatter plot of `education vs income`:

```{r}
ggplot(df, aes(x = education, y = income)) +
  geom_point() +
  labs(title = "Scatter Plot of Education vs Income", x = "Education", y = "Income")
```

- Linear regression on the observed data:

```{r}
ggplot(df, aes(x=education, y=income)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="Regression Plot: Education vs. Income", x="Education", y="Income")
```

As the result above shows, ... TODO

4.- Consider the polynomial regression model. How well does the polynomial model fit the data? Compare the R2 of both linear and polynomial models. What do you conclude?

```{r}
model <- lm(income ~ poly(education, 2), data = df)

scatter_plot <- ggplot(df, aes(x = education, y = income)) +
  geom_point() +
  labs(title = "Education vs Income", x = "Education", y = "Income")

scatter_plot + geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, col = "red") +
  labs(title = "Polynomial Regression: Education vs Income")
```

As it can be seeing above, the polynomial regression model ($R^2$), ... TODO

- Comparation between the Linear regression and Polynomial regression model, side to side:

```{r}
linear_reg_plot <- ggplot(df, aes(x=education, y=income)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="Regression Plot: Education vs. Income", x="Education", y="Income")

scatter_plot <- ggplot(df, aes(x = education, y = income)) +
  geom_point() +
  labs(title = "Education vs Income", x = "Education", y = "Income")

poly_reg_plot <- scatter_plot + geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, col = "red") + labs(title = "Polynomial Regression: Education vs Income")

grid_layout <- grid.arrange(
  linear_reg_plot,
  poly_reg_plot,
  ncol = 2
)
grid_layout
```

It can be seeing that, ... TODO

So it can be concluded that, ... TODO

5.- Would some transformation procedure of the variables, such as log or square root, allow for a better model? Try out different transformations and plot the transformed variables. Which transformation is the "best"? For the best transformation, fit a regression model.

-  Some transformation of the variables can be the following:

```{r}
# Log transformation
df$income_log <- log(df$income)
df$education_log <- log(df$education)

# Sqrt transformation
df$income_sqrt <- sqrt(df$income)
df$education_sqrt <- sqrt(df$education)

# Square transformation
df$income_sqr <- df$income^2
df$education_sqr <- df$education^2
```

-  A function can be defined to get the Linear regression vs Polynomial regression models plots:

```{r}
linear_vs_ploy_plot <- function(df, x, y) {
  linear_reg_plot <- ggplot(df, aes(x = !!rlang::sym(x), y = !!rlang::sym(y))) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +
    labs(title = paste("Regression Plot:", x, "vs.", y), x = x, y = y)

  scatter_plot <- ggplot(df, aes(x = !!rlang::sym(x), y = !!rlang::sym(y))) +
    geom_point() +
    labs(title = paste(x, "vs", y), x = x, y = y)

  poly_reg_plot <- scatter_plot + geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE, col = "red") +
    labs(title = paste("Polynomial Regression:", x, "vs.", y))

  list(linear_reg_plot = linear_reg_plot, poly_reg_plot = poly_reg_plot)
}
```

Now, that `linear_vs_ploy_plot` function can be applied to the transformations:

```{r}
log_plots <- linear_vs_ploy_plot(df, "education_log", "income_log")
sqrt_plots <- linear_vs_ploy_plot(df, "education_sqrt", "income_sqrt")
sqr_plots <- linear_vs_ploy_plot(df, "education_sqr", "income_sqr")
```

- Log transformations:

```{r}
grid_layout <- grid.arrange(
  log_plots$linear_reg_plot,
  log_plots$poly_reg_plot,
  ncol = 2
)
grid_layout
```

- Square root transformations:

```{r}
grid_layout <- grid.arrange(
  sqrt_plots$linear_reg_plot,
  sqrt_plots$poly_reg_plot,
  ncol = 2
)
grid_layout
```

- Square transformations:

```{r}
grid_layout <- grid.arrange(
  sqr_plots$linear_reg_plot,
  sqr_plots$poly_reg_plot,
  ncol = 2
)
grid_layout
```

The "best" transformation is ..., TODO
