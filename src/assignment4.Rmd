---
title: "Assignment 4 - Clustering models for Penguindata dataset"
author: "Sergi Mayol and Toni Garri"
date: "`r Sys.Date()`"
output: html_document
---

## Introduction

The dataset includes measurements taken for penguins in Palmer Archipelago.

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Study Problem Statement

The objective of this assignment is to see how penguins can be grouped.

## Libraries

For this assignment, the following libraries are used:

```{r library_load}
library(GGally)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ggcorrplot)
library(dendextend)
library(dbscan)
library(factoextra)
library(mclust)
library(cluster)
library(igraph)
library(clValid)
library(cluster)
```

# Data

This assignment uses the data frame Cirrhosis dataset that can be found in the DATASET folder.

```{r dataset_load}
dataset <- read.csv("../datasets/penguindata.csv")
```

## Data preparation

Let's study the dataset to see which data will be useful to our study. First of all let's transform to factor the variable `sex`, a character, to see in the summary all the NA's.

```{r}
temp_dataset <- dataset
temp_dataset$sex <- as.factor(temp_dataset$sex)
summary(temp_dataset)
```

As we can see there are not a lot of missing values, we could simply remove this data, but in our case let's transform the data to something more useful.

Another important thing to do previous to deal with the NA's is seeing the type of the data:

```{r}
str(dataset)
```

Once we have taken a look to the data we can simplify the name of the dataset to `df` to also keep the original without modifications.

```{r}
df <- dataset
```

We can remove the X from the dataset because it's a value that is used only to index the data and has no other important relation with the rest.

```{r}
df <- subset(df, select = -X)
```

And now let's clean the data. In this case the variable `sex` it's a chr data we change the NA for the median, when is a numeric we use the mean of that variable except for Year that we use the median because it does not make sense to have half a year in which the study was taken.

```{r}

df <- df %>% mutate(bill_length_mm = ifelse(is.na(bill_length_mm), mean(bill_length_mm, na.rm = TRUE), bill_length_mm))
df <- df %>% mutate(bill_depth_mm = ifelse(is.na(bill_depth_mm), mean(bill_depth_mm, na.rm = TRUE), bill_depth_mm))
df <- df %>% mutate(flipper_length_mm = ifelse(is.na(flipper_length_mm), mean(flipper_length_mm, na.rm = TRUE), flipper_length_mm))
df <- df %>% mutate(body_mass_g = ifelse(is.na(body_mass_g), mean(body_mass_g, na.rm = TRUE), body_mass_g))
df <- df %>% mutate(sex = ifelse(is.na(sex), median(sex, na.rm = TRUE), sex))
df <- df %>% mutate(year = ifelse(is.na(year), median(year, na.rm = TRUE), year))
summary(df)
```

Now let's change `sex` and `year` to a numeric and to a smaller numbers respectively to have the possibility to use them in the clustering.

```{r}
df$sex <- as.numeric(as.factor(df$sex))
df$year <- as.numeric(as.factor(df$year))

summary(df)
str(df)
```

## Models

Once the data is prepared, it's ready to be used in the models. In this case we have:

- Hierarchical:
  - AGNES (Agglomerative Nesting)
  
- Partitional:
  - K-Means Clustering
  - Gaussian Mixture Model
  - PAM
  
- Density-Based
  - DBSCAN
  
- Ordering-Based
  - OPTICS (Ordering Point to Identify the Clustering Structure)

Each run of the model will output the confusion matrix and the evaluation of each run. Later on, it will be studied and commented on in the `Results` section. Additionally, the results of each run will be displayed immediately after every model, as shown in the following sections for each model.

```{r}
set.seed(2828)
```

Before jumping to the models it is important to transform all the data to be the same type, in this case numeric.

```{r}
penguins <- df
penguins$bill_length_mm <- as.numeric(penguins$bill_length_mm)
penguins$bill_depth_mm <- as.numeric(penguins$bill_depth_mm)
penguins$flipper_length_mm <- as.numeric(penguins$flipper_length_mm)
penguins$body_mass_g <- as.numeric(penguins$body_mass_g)

summary(penguins)
str(penguins)
```

Also is important to scale the features that will be used to make a good clustering.

```{r}
features <- penguins[, c("sex", "year", "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g")]
scaled_features <- scale(features)
```

```{r}
fviz_nbclust(
  x = penguins, FUNcluster = pam, method = "wss", k.max = 15,
  diss = dist(penguins, method = "manhattan")
)
```

```{r}
matriz_distancias <- dist(x = penguins, method = "euclidean")

hc_euclidea_completo <- hclust(d = matriz_distancias, method = "complete")
hc_euclidea_single <- hclust(d = matriz_distancias, method = "single")
hc_euclidea_average <- hclust(d = matriz_distancias, method = "average")

grid.arrange(
  plot(
    x = hc_euclidea_completo, cex = 0.6, xlab = "", ylab = "", sub = "",
    main = "Linkage complete"
  ),
  plot(
    x = hc_euclidea_single, cex = 0.6, xlab = "", ylab = "", sub = "",
    main = "Linkage single"
  ),
  plot(
    x = hc_euclidea_average, cex = 0.6, xlab = "", ylab = "", sub = "",
    main = "Linkage average"
  ),
  nrow = 2
)
```

### Hierarchical

#### AGNES Clustering

```{r}
agnes_result <- agnes(scaled_features)

fviz_dend(agnes_result,
  main = "AGNES Clustering Dendrogram",
  show_labels = FALSE,
  palette = "jama",
  k = 5,
  color_labels_by_k = TRUE,
  ggtheme = theme_classic()
)
```

### Partitional

##### K-Means Clustering

```{r}
k <- 3
kmeans_result <- kmeans(scaled_features, centers = k)
penguins$cluster <- kmeans_result$cluster

plot(penguins[, c(1:6)], col = kmeans_result$cluster)
title("Pair Plot: Scatter Plots of Numeric Variables by Cluster")
```

```{r}
fviz_cluster(
  object = kmeans_result, data = penguins, show.clust.cent = TRUE,
  ellipse.type = "euclid", star.plot = TRUE, repel = TRUE
) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
hclust_result <- hclust(dist(scaled_features))

dend_colored <- color_branches(hclust_result, k = k)

labels(dend_colored) <- NULL

plot(dend_colored, cex = 0.6, main = "Hierarchical Clustering Dendrogram")
rect.hclust(hclust_result, k, border = "black")
```

```{r}
grid.arrange(
  fviz_dend(
    x = hclust_result,
    k = k,
    color_labels_by_k = TRUE,
    cex = 0.8,
    type = "phylogenic",
    repel = TRUE,
    xlab = "",
    ylab = ""
  ),
  fviz_dend(
    x = hclust_result,
    k = k,
    color_labels_by_k = TRUE,
    cex = 0.5,
    type = "circular",
  ),
  nrow = 1
)
```

```{r}
k <- 4
kmeans_result <- kmeans(scaled_features, centers = k)
penguins$cluster <- kmeans_result$cluster

plot(penguins[, c(1:6)], col = kmeans_result$cluster)
title("Pair Plot: Scatter Plots of Numeric Variables by Cluster")
```

```{r}
fviz_cluster(
  object = kmeans_result, data = penguins, show.clust.cent = TRUE,
  ellipse.type = "euclid", star.plot = TRUE, repel = TRUE
) +
  labs(title = "Resultados clustering K-means") +
  theme_bw() +
  theme(legend.position = "none")
```

```{r plot_fviz_cluster function}
plot_fviz_cluster <- function(features, dt, cents) {
  plot <- fviz_cluster(
    object = kmeans(features, centers = cents),
    data = dt,
    show.clust.cent = FALSE,
    ellipse.type = "euclid", star.plot = TRUE, repel = TRUE,
    show.dist = FALSE,
    xlab = "",
    ylab = ""
  ) +
    labs(title = paste("K-means ", cents)) +
    theme_bw() +
    theme(legend.position = "none")

  return(plot)
}
```

```{r self-similarity plots}
grid.arrange(
  plot_fviz_cluster(scaled_features, penguins, 5),
  plot_fviz_cluster(scaled_features, penguins, 6),
  ncol = 2
)
grid.arrange(
  plot_fviz_cluster(scaled_features, penguins, 7),
  plot_fviz_cluster(scaled_features, penguins, 8),
  ncol = 2
)
```

```{r}
hclust_result <- hclust(dist(scaled_features))

dend_colored <- color_branches(hclust_result, k = k)

labels(dend_colored) <- NULL

plot(dend_colored, cex = 0.6, main = "Hierarchical Clustering Dendrogram")

rect.hclust(hclust_result, k, border = "black")
```

```{r}
grid.arrange(
  fviz_dend(
    x = hclust_result,
    k = k,
    color_labels_by_k = TRUE,
    cex = 0.8,
    type = "phylogenic",
    repel = TRUE,
    xlab = "",
    ylab = ""
  ),
  fviz_dend(
    x = hclust_result,
    k = k,
    color_labels_by_k = TRUE,
    cex = 0.5,
    type = "circular",
    show_labels = FALSE
  ),
  nrow = 1
)
```

#### Gaussian Mixture Model Clustering

```{r}
gmm_result <- Mclust(scaled_features)
plot(gmm_result, what = "classification", main = "GMM Clustering")
```

#### PAM Clustering

```{r PAM Clustering k 3}
pam_result <- pam(dist(scaled_features, method = "euclidean"), 3)
clusplot(pam_result)
```

```{r PAM Clustering k 4}
pam_result <- pam(dist(scaled_features, method = "euclidean"), 4)
clusplot(pam_result)
```

### Density-Based

#### DBSCAN Clustering

```{r}
dbscan_result <- dbscan(scaled_features, 
                        eps = 1.5, 
                        MinPts = 4)
fviz_cluster(
  object = dbscan_result, data = scaled_features, stand = FALSE,
  geom = "point", ellipse = TRUE, show.clust.cent = TRUE,
  pallete = "jco",
  main = "DBSCAN Clustering"
) +
  theme_bw() +
  theme(legend.position = "bottom")
```

### Ordering-Based

#### OPTICS Clustering

```{r}
optics_result <- optics(scaled_features, minPts = 4)
plot(optics_result, main = "OPTICS Clustering")
```

### Results

```{r}
comparacion <- clValid(
  obj        = scaled_features,
  nClust     = 2:6,
  clMethods  = c("hierarchical", "kmeans", "pam", "agnes"),
  validation = c("stability", "internal")
)
summary(comparacion)
```
